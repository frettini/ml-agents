{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from mlagents.torch_utils.torch import torch\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "from mlagents.plugins.bvh_utils.visualize import skeletons_plot, motion_animation\r\n",
    "from mlagents.plugins.dataset.dataset import SkeletonInfo\r\n",
    "import mlagents.plugins.bvh_utils.lafan_utils as utils\r\n",
    "from mlagents.plugins.dataset.skeleton_side_channel import Skeleton_SideChannel \r\n",
    "\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from IPython.display import HTML\r\n",
    "%matplotlib qt\r\n",
    "\r\n",
    "\r\n",
    "from mlagents_envs.environment import UnityEnvironment"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# INITIALIZATION OF UNITY SAVED DATA AND UNITY ENV"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "motion_path = \"../ml-agents/mlagents/plugins/skeleton_aware_op/data/LaFan/Real_Data/\"\r\n",
    "# motion_path = \"../../LaFan_BVH/rotation_test/\"\r\n",
    "skdata = SkeletonInfo(motion_path, xyz='xyz')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# Setup Unity Environment + sidechannel\r\n",
    "skeleton_sidechannel = Skeleton_SideChannel()\r\n",
    "\r\n",
    "try:\r\n",
    "    env.close()\r\n",
    "except:\r\n",
    "    pass\r\n",
    "\r\n",
    "# filename = None enables to communicate directly with the unity editor\r\n",
    "env = UnityEnvironment(file_name=None, seed=1, side_channels=[skeleton_sidechannel])\r\n",
    "env.reset()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DATA RETRIVAL FROM FILE AND ENV"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "with open('walk1_subject1_csv.txt') as f:\r\n",
    "    lines = f.readlines()\r\n",
    "\r\n",
    "n_lines = len(lines)\r\n",
    "n_features = len(lines[0].split(','))\r\n",
    "\r\n",
    "features = torch.zeros((n_lines,n_features)).float()\r\n",
    "\r\n",
    "for i, line in enumerate(lines):\r\n",
    "    line = line\r\n",
    "    line_array = [float(f) for f in line.split(',')]\r\n",
    "    features[i] = torch.tensor(line_array).float()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "skdata.parents"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([-1,  0,  1,  2,  3,  0,  5,  6,  7,  0,  9, 10, 11, 12, 11, 14, 15,\n",
       "       16, 11, 18, 19, 20])"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "behavior_name = list(env.behavior_specs)[0]\r\n",
    "spec = env.behavior_specs[behavior_name]\r\n",
    "env.reset()\r\n",
    "\r\n",
    "# get action and obs dimension\r\n",
    "state_dim = spec.observation_specs[0].shape[0]\r\n",
    "action_dim = spec.action_spec.continuous_size\r\n",
    "\r\n",
    "decision_steps, terminal_steps = env.get_steps(behavior_name)\r\n",
    "\r\n",
    "unity_data = []\r\n",
    "\r\n",
    "for i in range(60):\r\n",
    "    decision_steps, terminal_steps = env.get_steps(behavior_name)\r\n",
    "    unity_data.append(decision_steps.obs[0])\r\n",
    "    \r\n",
    "    # Generate an action for all agents\r\n",
    "    action = spec.action_spec.empty_action(len(decision_steps))\r\n",
    "\r\n",
    "    # Set the actions\r\n",
    "    env.set_actions(behavior_name, action)\r\n",
    "\r\n",
    "    # Move the simulation forward\r\n",
    "    env.step()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DATA PROCESSING"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "features  = features.reshape(features.shape[0],skdata.num_joints,7)\r\n",
    "\r\n",
    "csv_positions = features[:,:,:3]\r\n",
    "csv_rotations = features[:,:,3:]\r\n",
    "csv_local_positions = csv_positions[:] - csv_positions[:,0:1,:]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "n = 54\r\n",
    "\r\n",
    "features_per_joint = 13\r\n",
    "\r\n",
    "obs = torch.cat([torch.tensor(unity_data[f]).float() for f in range(60)],dim=0).float()\r\n",
    "print(obs.shape)\r\n",
    "\r\n",
    "# extract only the observation corresponding to the joints\r\n",
    "joint_features = obs[0:n,:-6]\r\n",
    "print(joint_features.shape)\r\n",
    "joint_features = joint_features.reshape(n,-1, 13)\r\n",
    "\r\n",
    "init_rotations = torch.tensor(skeleton_sidechannel.msg[:22*4]).float().reshape(22,4)\r\n",
    "init_positions = torch.tensor(skeleton_sidechannel.msg[22*4:]).float().reshape(22,3)\r\n",
    "\r\n",
    "# extract information from the observation vector\r\n",
    "env_velocity = joint_features[:,:,:3].clone()\r\n",
    "env_angular_vel = joint_features[:,:,3:6].clone()\r\n",
    "env_positions = joint_features[:,:,6:9].clone()\r\n",
    "env_rotations = joint_features[:,:,9:].clone()\r\n",
    "\r\n",
    "# unity rotation is x,y,z,w and lafan is w,x,y,z, change to the latter\r\n",
    "temp = env_rotations[:,:,3].clone()\r\n",
    "env_rotations[:,:,1:] = env_rotations[:,:,:3] \r\n",
    "env_rotations[:,:,0] = temp\r\n",
    "\r\n",
    "env_local_positions = env_positions[:] - env_positions[:,0:1,:]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([59, 292])\n",
      "torch.Size([54, 286])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# reconstruct pose from rotations\r\n",
    "offsets = init_positions.clone()\r\n",
    "offsets = offsets.reshape(1,22,3)\r\n",
    "offsets = offsets.repeat(env_rotations.shape[0],1,1)\r\n",
    "\r\n",
    "env_rotations[:,0,:] = torch.tensor([1.,0.,0.,0.]).float()\r\n",
    "csv_rotations[:,0,:] = torch.tensor([1.,0.,0.,0.]).float()\r\n",
    "\r\n",
    "_, env_pos_from_rot = utils.quat_fk(env_rotations, offsets, skdata.parents)\r\n",
    "_, csv_pos_from_rot = utils.quat_fk(csv_rotations[:env_rotations.shape[0],:,:], offsets, skdata.parents)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# VISUALIZE"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "# POSE FROM POSITIONS\r\n",
    "limits = [[-1,1],[-1,1],[-1,1]]\r\n",
    "# fig, ax = skeletons_plot([csv_local_positions[100].cpu().detach(), env_local_positions[20].cpu().detach()], [skdata.edges, skdata.edges], ['g', 'b'], limits=limits, return_plot=True)\r\n",
    "fig,ax=skeletons_plot([csv_local_positions[0].cpu().detach()], [skdata.edges], ['g'], limits=limits, return_plot=True)\r\n",
    "\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "# POSE FROM ROTATIONS\r\n",
    "limits = [[-1,1],[-1,1],[-1,1]]\r\n",
    "fig,ax=skeletons_plot([csv_pos_from_rot[0].cpu().detach(), env_pos_from_rot[1].cpu().detach()], [skdata.edges, skdata.edges], ['g', 'b'], limits=limits, return_plot=True)\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "# MOTION FROM POSITIONS\r\n",
    "anim = motion_animation([csv_local_positions[:55].cpu().detach(), env_local_positions.cpu().detach()], [skdata.edges, skdata.edges], ['g', 'b'], limits)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "c:\\users\\nicol\\work\\master\\dissertation\\ml-agents\\ml-agents\\mlagents\\plugins\\bvh_utils\\visualize.py:151: MatplotlibDeprecationWarning: Axes3D(fig) adding itself to the figure is deprecated since 3.4. Pass the keyword argument auto_add_to_figure=False and use fig.add_axes(ax) to suppress this warning. The default value of auto_add_to_figure will change to False in mpl3.5 and True values will no longer work in 3.6.  This is consistent with other Axes classes.\n",
      "  ax = p3.Axes3D(fig)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "env.close()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('mla-env': venv)"
  },
  "interpreter": {
   "hash": "98f98e15727b138dbe83789526665a788b00fc73f5809a42725d22ab43def4cd"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}