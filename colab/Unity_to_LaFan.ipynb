{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('mla-env': venv)"
  },
  "interpreter": {
   "hash": "98f98e15727b138dbe83789526665a788b00fc73f5809a42725d22ab43def4cd"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from datetime import datetime\r\n",
    "import time\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import mlagents\r\n",
    "from mlagents_envs.environment import UnityEnvironment\r\n",
    "\r\n",
    "from mlagents.torch_utils import torch, default_device, set_torch_config\r\n",
    "from mlagents.plugins.bvh_utils.visualize import skeletons_plot\r\n",
    "import mlagents.plugins.bvh_utils.lafan_utils as utils\r\n",
    "from mlagents.plugins.skeleton_aware_op.dataset import TemporalMotionData, SkeletonInfo\r\n",
    "from mlagents.plugins.skeleton_aware_op.options import get_options as get_options_sk\r\n",
    "\r\n",
    "from mlagents_envs.side_channel.side_channel import (\r\n",
    "    SideChannel,\r\n",
    "    IncomingMessage,\r\n",
    "    OutgoingMessage,\r\n",
    ")\r\n",
    "import uuid\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from mlagents.plugins.bvh_utils.Quaternions import Quaternions\r\n",
    "%matplotlib qt\r\n",
    "\r\n",
    "torch.set_printoptions(precision=4)\r\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def reorder(xyz, data):\r\n",
    "\r\n",
    "    if isinstance(data, np.ndarray):\r\n",
    "        temp = data.copy()\r\n",
    "    elif isinstance(data, torch.Tensor):\r\n",
    "        temp = data.clone()\r\n",
    "\r\n",
    "    # reorder to fit the frame of reference\r\n",
    "    for ind, letter in enumerate(xyz):\r\n",
    "        \r\n",
    "        if letter == 'x':\r\n",
    "            data[..., ind] = temp[..., 0]\r\n",
    "        elif letter == 'y':\r\n",
    "            data[..., ind] = temp[..., 1]\r\n",
    "        elif letter == 'z':\r\n",
    "            data[..., ind] = temp[..., 2]\r\n",
    "\r\n",
    "    return data\r\n",
    "\r\n",
    "class Skeleton_SideChannel(SideChannel):\r\n",
    "    def __init__(self) -> None:\r\n",
    "        super().__init__(uuid.UUID(\"621f0a70-4f87-11ea-a6bf-784f4387d1f7\"))\r\n",
    "\r\n",
    "    def on_message_received(self, msg: IncomingMessage) -> None:\r\n",
    "        \"\"\"\r\n",
    "        Note: We must implement this method of the SideChannel interface to\r\n",
    "        receive messages from Unity\r\n",
    "        \"\"\"\r\n",
    "        self.msg = msg.read_float32_list()\r\n",
    "        # We simply read a string from the message and print it.\r\n",
    "        print(msg.read_float32_list())\r\n",
    "\r\n",
    "    def send_string(self, data: str) -> None:\r\n",
    "        pass\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Setup Unity Environment + sidechannel\r\n",
    "skeleton_sidechannel = Skeleton_SideChannel()\r\n",
    "\r\n",
    "try:\r\n",
    "    env.close()\r\n",
    "except:\r\n",
    "    pass\r\n",
    "\r\n",
    "# filename = None enables to communicate directly with the unity editor\r\n",
    "env = UnityEnvironment(file_name=None, seed=1, side_channels=[skeleton_sidechannel])\r\n",
    "env.reset()\r\n",
    "\r\n",
    "# Setup LaFan skeleton data\r\n",
    "# Get skeleton data from dataset\r\n",
    "motion_path = \"../ml-agents/mlagents/plugins/skeleton_aware_op/data/LaFan/Real_Data/\"\r\n",
    "# motion_path = \"../../LaFan_BVH/rotation_test/\"\r\n",
    "skdata = SkeletonInfo(motion_path, xyz='zxy')\r\n",
    "\r\n",
    "# get lafan motion rotations\r\n",
    "motion_path = \"../ml-agents/mlagents/plugins/skeleton_aware_op/data/LaFan/Real_Data/\"\r\n",
    "lafan_dataset = TemporalMotionData(motion_path, recalculate_mean_var=True, normalize_data=True, xyz='zxy', rot_order=None)\r\n",
    "skdata = lafan_dataset.skdata\r\n",
    "\r\n",
    "options_sk = get_options_sk()\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[]\n",
      "[DATASET] final data shape :  torch.Size([29, 88, 16])\n",
      "[DATASET] input concatenated shape:  torch.Size([464, 88])\n",
      "[DATASET] mean shape:  torch.Size([1, 88])\n",
      "[DATASET] var shape:  torch.Size([1, 88])\n",
      "[DATASET] mean var shape : torch.Size([2, 88, 1])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "behavior_name = list(env.behavior_specs)[0]\r\n",
    "spec = env.behavior_specs[behavior_name]\r\n",
    "env.reset()\r\n",
    "\r\n",
    "# get action and obs dimension\r\n",
    "state_dim = spec.observation_specs[0].shape[0]\r\n",
    "action_dim = spec.action_spec.continuous_size\r\n",
    "\r\n",
    "decision_steps, terminal_steps = env.get_steps(behavior_name)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Generate an action for all agents\r\n",
    "action = spec.action_spec.random_action(len(decision_steps))\r\n",
    "\r\n",
    "# Set the actions\r\n",
    "env.set_actions(behavior_name, action)\r\n",
    "\r\n",
    "# Move the simulation forward\r\n",
    "env.step()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "features_per_joint = 13\r\n",
    "obs = decision_steps.obs[0]\r\n",
    "\r\n",
    "# extract only the observation corresponding to the joints\r\n",
    "joint_features = obs[0,3:]\r\n",
    "joint_features = joint_features.reshape(-1, 13)\r\n",
    "\r\n",
    "init_rotations = torch.tensor(skeleton_sidechannel.msg[:22*4]).float().reshape(22,4)\r\n",
    "init_positions = torch.tensor(skeleton_sidechannel.msg[22*4:]).float().reshape(22,3)\r\n",
    "\r\n",
    "# extract information from the observation vector\r\n",
    "velocity = torch.tensor(joint_features[:,:3].copy()).float()\r\n",
    "angular_vel = torch.tensor(joint_features[:,3:6].copy()).float()\r\n",
    "positions = torch.tensor(joint_features[:,6:9].copy()).float()\r\n",
    "rotations = torch.tensor(joint_features[:,9:].copy()).float()\r\n",
    "\r\n",
    "# unity rotation is x,y,z,w and lafan is w,x,y,z, change to the latter\r\n",
    "temp = rotations[:,3].clone()\r\n",
    "rotations[:,1:] = rotations[:,:3] \r\n",
    "rotations[:,0] = temp\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "scale = 100\r\n",
    "\r\n",
    "# unit rotations, used to get ini\r\n",
    "unit_rotations = torch.tensor([[1.,0.,0.,0.]])\r\n",
    "unit_rotations = unit_rotations.repeat(22,1)\r\n",
    "\r\n",
    "# get the unity offset from the init positions -> local position\r\n",
    "unity_offsets = init_positions.clone()\r\n",
    "unity_offsets[0,:] = torch.tensor([0,0,0])\r\n",
    "\r\n",
    "# get lafan offset, scale corrected\r\n",
    "lafan_offsets = skdata.offsets.clone()/scale\r\n",
    "\r\n",
    "# get the current unity local pose (unit global rotation)\r\n",
    "rotations_local = rotations.clone()\r\n",
    "rotations_local[0,:] = torch.tensor([1.,0.,0.,0.]).float()\r\n",
    "_, unity_pos_local = utils.quat_fk(rotations_local, unity_offsets, skdata.parents)\r\n",
    "\r\n",
    "# get some data from the dataset\r\n",
    "motion_data = lafan_dataset[20:22]\r\n",
    "motion_data = lafan_dataset.denormalize(motion_data)\r\n",
    "\r\n",
    "# we want to add a rotation offset on top of the local pos to align it with unity\r\n",
    "# for dataset zxy -> euler rotation ->(0,0,-90) \r\n",
    "rotation_offset = torch.tensor([  0.7071068 ,0, 0, 0.7071068])#Quaternions.from_euler(np.array([0,0,0]), 'xyz').qs)\r\n",
    "lafan_pos, lafan_pos_local, lafan_glob, lafan_glob_velo, lafan_vel = utils.get_pos_info_from_raw(motion_data, skdata, lafan_offsets, options_sk, norm_rot=False, rotation_offset=rotation_offset)\r\n",
    "\r\n",
    "limits = [[-1,1],[-1,1],[-1,1]]\r\n",
    "fig, ax = skeletons_plot([unity_pos_local.cpu().detach(), lafan_pos_local[0,0].cpu().detach()], [skdata.edges, skdata.edges], ['g', 'b'], limits=limits, return_plot=True)\r\n",
    "plt.show()\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([2, 16, 4])\n",
      "torch.Size([2, 16, 4])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "scale = 100\r\n",
    "\r\n",
    "# unit rotations, used to get ini\r\n",
    "unit_rotations = torch.tensor([[1.,0.,0.,0.]])\r\n",
    "unit_rotations = unit_rotations.repeat(22,1)\r\n",
    "\r\n",
    "# get the unity offset from the init positions -> local position\r\n",
    "unity_offsets = init_positions.clone()\r\n",
    "unity_offsets[0,:] = torch.tensor([0,0,0])\r\n",
    "\r\n",
    "# get lafan offset that aligns\r\n",
    "lafan_offsets = skdata.offsets.clone()/scale\r\n",
    "\r\n",
    "# initial offsets, obtained by doing fk with unit rotations\r\n",
    "_, unity_init_offset = utils.quat_fk(unit_rotations, unity_offsets, skdata.parents)\r\n",
    "_, lafan_init_offset = utils.quat_fk(unit_rotations, lafan_offsets, skdata.parents)\r\n",
    "\r\n",
    "# t pose using the initial rotation for both dataset\r\n",
    "_, unity_t_pose = utils.quat_fk(init_rotations, unity_offsets, skdata.parents)\r\n",
    "_, lafan_t_pose = utils.quat_fk(init_rotations, lafan_offsets, skdata.parents)\r\n",
    "\r\n",
    "\r\n",
    "limits = [[-1,1],[-1,1],[-1,1]]\r\n",
    "fig, ax = skeletons_plot([unity_init_offset.cpu().detach(), lafan_init_offset.cpu().detach()], [skdata.edges, skdata.edges], ['g', 'b'], limits=limits, return_plot=True)\r\n",
    "plt.show()\r\n",
    "limits = [[-1,1],[-1,1],[-1,1]]\r\n",
    "fig, ax = skeletons_plot([unity_t_pose.cpu().detach(), lafan_t_pose.cpu().detach()], [skdata.edges, skdata.edges], ['g', 'b'], limits=limits, return_plot=True)\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# t pose using the initial rotation for both dataset\r\n",
    "_, unity_pos = utils.quat_fk(rotations, unity_offsets, skdata.parents)\r\n",
    "_, lafan_pos = utils.quat_fk(rotations, lafan_offsets, skdata.parents)\r\n",
    "\r\n",
    "rotations_local = rotations.clone()\r\n",
    "rotations_local[0,:] = torch.tensor([1.,0.,0.,0.]).float()\r\n",
    "_, unity_pos_local = utils.quat_fk(rotations_local, unity_offsets, skdata.parents)\r\n",
    "\r\n",
    "limits = [[-1,1],[-1,1],[-1,1]]\r\n",
    "fig, ax = skeletons_plot([unity_pos.cpu().detach(), lafan_pos.cpu().detach()], [skdata.edges, skdata.edges], ['g', 'b'], limits=limits, return_plot=True)\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Setup LaFan skeleton data\r\n",
    "# Get skeleton data from dataset\r\n",
    "motion_path = \"../ml-agents/mlagents/plugins/skeleton_aware_op/data/LaFan/Real_Data/\"\r\n",
    "# motion_path = \"../../LaFan_BVH/rotation_test/\"\r\n",
    "skdata = SkeletonInfo(motion_path, xyz='zxy')\r\n",
    "\r\n",
    "# get lafan motion rotations\r\n",
    "motion_path = \"../ml-agents/mlagents/plugins/skeleton_aware_op/data/LaFan/Real_Data/\"\r\n",
    "lafan_dataset = TemporalMotionData(motion_path, recalculate_mean_var=True, normalize_data=True, xyz='zxy', rot_order=None)\r\n",
    "skdata = lafan_dataset.skdata\r\n",
    "\r\n",
    "options_sk = get_options_sk()\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[DATASET] final data shape :  torch.Size([979, 88, 16])\n",
      "[DATASET] input concatenated shape:  torch.Size([15664, 88])\n",
      "[DATASET] mean shape:  torch.Size([1, 88])\n",
      "[DATASET] var shape:  torch.Size([1, 88])\n",
      "[DATASET] mean var shape : torch.Size([2, 88, 1])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "motion_data = lafan_dataset[20:22]\r\n",
    "print(motion_data.shape)\r\n",
    "motion_data = lafan_dataset.denormalize(motion_data)\r\n",
    "\r\n",
    "# get lafan offset that aligns\r\n",
    "lafan_offsets = skdata.offsets.clone()/100\r\n",
    "# lafan_offsets_r = lafan_offsets.reshape(1, 1, skdata.offsets.shape[0], skdata.offsets.shape[1])\r\n",
    "# lafan_offsets_r = lafan_offsets_r.repeat(2, 16, 1, 1)\r\n",
    "\r\n",
    "# we want to add a rotation offset on top of the local pos to align it with unity\r\n",
    "# for dataset zxy -> euler rotation ->(0,0,-90) \r\n",
    "# rotation_offset = torch.tensor([  0.7071068 ,0, 0, 0.7071068])#Quaternions.from_euler(np.array([0,0,0]), 'xyz').qs)\r\n",
    "# rotation_offset = torch.tensor([  1. ,0., 0., 0.])#Quaternions.from_euler(np.array([0,0,0]), 'xyz').qs)\r\n",
    "# rotation_offset = torch.tensor([  0.7071068 ,0.7071068, 0., 0.])#Quaternions.from_euler(np.array([0,0,0]), 'xyz').qs)\r\n",
    "rotation_offset = torch.tensor([ 0.5 ,-0.5, 0.5, 0.5])#Quaternions.from_euler(np.array([0,0,0]), 'xyz').qs)\r\n",
    "\r\n",
    "lafan_pos, lafan_pos_local, lafan_glob, lafan_glob_velo, lafan_vel = utils.get_pos_info_from_raw(motion_data, skdata, lafan_offsets, options_sk, norm_rot=False, rotation_offset=rotation_offset)\r\n",
    "\r\n",
    "\r\n",
    "limits = [[-1,1],[-1,1],[-1,1]]\r\n",
    "fig, ax = skeletons_plot([ lafan_pos_local[0,0].cpu().detach()], [skdata.edges], ['b'], limits=limits, return_plot=True)\r\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([2, 88, 16])\n",
      "torch.Size([2, 16, 4])\n",
      "torch.Size([2, 16, 4])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "env.close()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ]
}