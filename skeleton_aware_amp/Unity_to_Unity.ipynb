{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from mlagents.torch_utils.torch import torch\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "from mlagents.plugins.bvh_utils.visualize import skeletons_plot, motion_animation\r\n",
    "from mlagents.plugins.dataset.dataset import SkeletonInfo\r\n",
    "import mlagents.plugins.bvh_utils.lafan_utils as utils\r\n",
    "from mlagents.plugins.dataset.skeleton_side_channel import Skeleton_SideChannel \r\n",
    "\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from IPython.display import HTML\r\n",
    "%matplotlib qt\r\n",
    "\r\n",
    "from mlagents_envs.environment import UnityEnvironment"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# INITIALIZATION OF UNITY SAVED DATA AND UNITY ENV"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "motion_path = \"../ml-agents/mlagents/plugins/skeleton_aware_op/data/LaFan/Real_Data/\"\r\n",
    "# motion_path = \"../../LaFan_BVH/rotation_test/\"\r\n",
    "skdata = SkeletonInfo(skdata_path = './data_legs/skdata.txt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Setup Unity Environment + sidechannel\r\n",
    "skeleton_sidechannel = Skeleton_SideChannel()\r\n",
    "\r\n",
    "try:\r\n",
    "    env.close()\r\n",
    "except:\r\n",
    "    pass\r\n",
    "\r\n",
    "# filename = None enables to communicate directly with the unity editor\r\n",
    "env = UnityEnvironment(file_name=None, seed=1, side_channels=[skeleton_sidechannel])\r\n",
    "env.reset()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DATA RETRIVAL FROM FILE AND ENV"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "with open('./data_legs/walk1_subject1_legs_csv.txt') as f:\r\n",
    "    lines = f.readlines()\r\n",
    "\r\n",
    "n_lines = len(lines)\r\n",
    "n_features = len(lines[0].split(','))\r\n",
    "\r\n",
    "features = torch.zeros((n_lines,n_features)).float()\r\n",
    "\r\n",
    "for i, line in enumerate(lines):\r\n",
    "    line = line\r\n",
    "    line_array = [float(f) for f in line.split(',')]\r\n",
    "    features[i] = torch.tensor(line_array).float()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "with open('./data_legs/skdata.txt') as f:\r\n",
    "    lines = f.readlines()\r\n",
    "\r\n",
    "# EXTRACT INITIAL INFO ABOUT SKELETON\r\n",
    "n_joints = int(lines[0][:-1])\r\n",
    "init_positions = torch.tensor( [float(f) for f in lines[1][:-1].split(',')] ).float().reshape(n_joints, 3)\r\n",
    "init_rotations =  torch.tensor( [float(f) for f in lines[2][:-1].split(',')] ).float().reshape(n_joints, 4)\r\n",
    "parents = [int(f) for f in lines[3][:-1].split(',')]\r\n",
    "frametime = float(lines[4][:-1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "behavior_name = list(env.behavior_specs)[0]\r\n",
    "spec = env.behavior_specs[behavior_name]\r\n",
    "env.reset()\r\n",
    "\r\n",
    "# get action and obs dimension\r\n",
    "state_dim = spec.observation_specs[0].shape[0]\r\n",
    "action_dim = spec.action_spec.continuous_size\r\n",
    "\r\n",
    "decision_steps, terminal_steps = env.get_steps(behavior_name)\r\n",
    "\r\n",
    "unity_data = []\r\n",
    "\r\n",
    "for i in range(60):\r\n",
    "    decision_steps, terminal_steps = env.get_steps(behavior_name)\r\n",
    "    unity_data.append(decision_steps.obs[0])\r\n",
    "    \r\n",
    "    # Generate an action for all agents\r\n",
    "    action = spec.action_spec.empty_action(len(decision_steps))\r\n",
    "\r\n",
    "    # Set the actions\r\n",
    "    env.set_actions(behavior_name, action)\r\n",
    "\r\n",
    "    # Move the simulation forward\r\n",
    "    env.step()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DATA PROCESSING"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "features  = features.reshape(features.shape[0],skdata.num_joints,10)\r\n",
    "\r\n",
    "csv_positions = features[:,:,:3]\r\n",
    "csv_rotations = features[:,:,3:7]\r\n",
    "csv_velocity = features[:,:,7:]\r\n",
    "csv_local_positions = csv_positions[:] - csv_positions[:,0:1,:]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "env_velocity[0:20,0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.7680, -0.6159,  0.4227],\n",
       "        [ 0.6556, -0.9629,  0.2581],\n",
       "        [ 0.5239, -1.0636,  0.3037],\n",
       "        [ 0.4717, -0.9220,  0.2196],\n",
       "        [ 0.5710, -0.0405,  0.4119],\n",
       "        [ 0.6274,  0.4310,  0.3977],\n",
       "        [ 0.6495,  0.4341,  0.3041],\n",
       "        [ 0.6799,  0.2477,  0.2422],\n",
       "        [ 0.7265,  0.0542,  0.1995],\n",
       "        [ 0.7712, -0.1483,  0.1213],\n",
       "        [ 0.8151, -0.3389,  0.0243],\n",
       "        [ 0.8701, -0.5066,  0.0640],\n",
       "        [ 0.9258, -0.7176,  0.3259],\n",
       "        [ 1.0055, -0.8989,  0.6287],\n",
       "        [ 1.1362, -1.0300,  0.8506],\n",
       "        [ 1.2830, -1.1897,  0.8983],\n",
       "        [ 1.4184, -1.4777,  0.8835],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.4268, -0.6792,  1.2210]])"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# EXTRACT INITIAL INFO ABOUT SKELETON\r\n",
    "n_joints = int(skeleton_sidechannel.msg[0])\r\n",
    "init_rotations = torch.tensor(skeleton_sidechannel.msg[1:1+n_joints*4]).float().reshape(n_joints,4)\r\n",
    "init_positions = torch.tensor(skeleton_sidechannel.msg[ 1+n_joints*4 : 1+n_joints*4 + n_joints*3 ]).float().reshape(n_joints,3)\r\n",
    "parents = [int(f) for f in skeleton_sidechannel.msg[ 1+n_joints*4 + n_joints*3 : -1 ]]\r\n",
    "frametime = skeleton_sidechannel.msg[ -1 ]"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'Skeleton_SideChannel' object has no attribute 'msg'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-f41a5d361ff9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# EXTRACT INITIAL INFO ABOUT SKELETON\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mn_joints\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mskeleton_sidechannel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0minit_rotations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mskeleton_sidechannel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mn_joints\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_joints\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0minit_positions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mskeleton_sidechannel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m[\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mn_joints\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m4\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mn_joints\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m4\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mn_joints\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m3\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_joints\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mparents\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mskeleton_sidechannel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m[\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mn_joints\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m4\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mn_joints\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m3\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Skeleton_SideChannel' object has no attribute 'msg'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "n = 54\r\n",
    "\r\n",
    "features_per_joint = 13\r\n",
    "\r\n",
    "obs = torch.cat([torch.tensor(unity_data[f]).float() for f in range(60)],dim=0).float()\r\n",
    "print(obs.shape)\r\n",
    "\r\n",
    "# extract only the observation corresponding to the joints\r\n",
    "joint_features = obs[0:n,:-6]\r\n",
    "print(joint_features.shape)\r\n",
    "joint_features = joint_features.reshape(n,-1, 13)\r\n",
    "\r\n",
    "\r\n",
    "# extract information from the observation vector\r\n",
    "env_velocity = joint_features[:,:,:3].clone()\r\n",
    "env_angular_vel = joint_features[:,:,3:6].clone()\r\n",
    "env_positions = joint_features[:,:,6:9].clone()\r\n",
    "env_rotations = joint_features[:,:,9:].clone()\r\n",
    "\r\n",
    "# unity rotation is x,y,z,w and lafan is w,x,y,z, change to the latter\r\n",
    "temp = env_rotations[:,:,3].clone()\r\n",
    "env_rotations[:,:,1:] = env_rotations[:,:,:3] \r\n",
    "env_rotations[:,:,0] = temp\r\n",
    "\r\n",
    "env_local_positions = env_positions[:] - env_positions[:,0:1,:]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([57, 162])\n",
      "torch.Size([54, 156])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "# extract velocity\r\n",
    "env_root_pos, env_glob_pos = utils.get_global_position_from_velocity(torch.tensor([0,0,0]).float(), env_velocity[:,0,:], 1, env_positions)\r\n",
    "csv_root_pos, csv_pos_from_vel = utils.get_global_position_from_velocity(torch.tensor([0,0,0]).float(), csv_velocity[:,0,:], 10, csv_positions)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "# reconstruct pose from rotations\r\n",
    "offsets = init_positions.clone()\r\n",
    "offsets = offsets.reshape(1,skdata.num_joints,3)\r\n",
    "offsets = offsets.repeat(env_rotations.shape[0],1,1)\r\n",
    "\r\n",
    "# env_rotations[:,0,:] = torch.tensor([1.,0.,0.,0.]).float()\r\n",
    "# csv_rotations[:,0,:] = torch.tensor([1.,0.,0.,0.]).float()\r\n",
    "\r\n",
    "_, env_pos_from_rot = utils.quat_fk(env_rotations, offsets, skdata.parents)\r\n",
    "\r\n",
    "# reconstruct pose from rotations\r\n",
    "offsets = init_positions.clone()\r\n",
    "offsets = offsets.reshape(1,skdata.num_joints,3)\r\n",
    "offsets = offsets.repeat(csv_rotations.shape[0],1,1)\r\n",
    "\r\n",
    "_, csv_pos_from_rot = utils.quat_fk(csv_rotations[:,:,:], offsets, skdata.parents)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# reconstruct the posiitons from velocity\r\n",
    "csv_pos_from_vel = torch.zeros_like(csv_velocity)\r\n",
    "csv_prev_pos = csv_local_positions[0]\r\n",
    "env_pos_from_vel = torch.zeros_like(env_velocity)\r\n",
    "env_prev_pos = env_local_positions[0]\r\n",
    "\r\n",
    "for i in range(1,csv_velocity.shape[0]):\r\n",
    "    csv_pos_from_vel[i-1,:] = csv_prev_pos\r\n",
    "    csv_prev_pos = csv_prev_pos + csv_velocity[i,:] * 0.05\r\n",
    "\r\n",
    "for i in range(1, env_velocity.shape[0]):\r\n",
    "    env_pos_from_vel[i-1,:] = env_prev_pos\r\n",
    "    env_prev_pos = env_prev_pos + env_velocity[i,:] * 0.05\r\n",
    "    if torch.abs(env_velocity[i].sum())<0.00001 :\r\n",
    "        env_prev_pos = env_local_positions[i]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# VISUALIZE"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# POSE FROM POSITIONS\r\n",
    "limits = [[-1,1],[-1,1],[-1,1]]\r\n",
    "fig, ax = skeletons_plot([csv_local_positions[100].cpu().detach(), env_local_positions[20].cpu().detach()], [skdata.edges, skdata.edges], ['g', 'b'], limits=limits, return_plot=True)\r\n",
    "# fig,ax=skeletons_plot([csv_local_positions[100].cpu().detach()], [skdata.edges], ['g'], limits=limits, return_plot=True)\r\n",
    "\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# POSE FROM ROTATIONS\r\n",
    "limits = [[-1,1],[-1,1],[-1,1]]\r\n",
    "fig,ax=skeletons_plot([csv_pos_from_rot[0].cpu().detach(), env_pos_from_rot[25].cpu().detach()], [skdata.edges, skdata.edges], ['g', 'b'], limits=limits, return_plot=True)\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "# MOTION FROM POSITIONS\r\n",
    "limits = [[-1,1],[-1,1],[-1,1]]\r\n",
    "# anim = motion_animation([csv_local_positions[:55].cpu().detach(), env_local_positions.cpu().detach()], [skdata.edges, skdata.edges], ['g', 'b'], limits)\r\n",
    "# anim = motion_animation([csv_local_positions[100:270].cpu().detach(), csv_pos_from_vel[100:270].cpu().detach()], [skdata.edges, skdata.edges], ['g', 'b'], limits)\r\n",
    "# anim = motion_animation([env_local_positions.cpu().detach(), env_pos_from_vel.cpu().detach()], [skdata.edges, skdata.edges], ['g', 'b'], limits)\r\n",
    "# anim = motion_animation([env_local_positions.cpu().detach(), env_pos_from_rot.cpu().detach()], [skdata.edges, skdata.edges], ['g', 'b'], limits)\r\n",
    "anim = motion_animation([csv_local_positions[100:270].cpu().detach(), csv_pos_from_rot[100:270].cpu().detach()], [skdata.edges, skdata.edges], ['g', 'b'], limits)\r\n",
    "# anim = motion_animation([csv_pos_from_vel[0:100].cpu().detach()], [skdata.edges], ['g'], limits)\r\n",
    "# HTML(anim.to_jshtml())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "env.close()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('mla-env': venv)"
  },
  "interpreter": {
   "hash": "98f98e15727b138dbe83789526665a788b00fc73f5809a42725d22ab43def4cd"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}